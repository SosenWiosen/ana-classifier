{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-08T21:53:54.772993Z",
     "start_time": "2024-12-08T21:53:54.758185Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "from keras.src.layers import Dropout\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "import tensorflow as tf"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:53:54.814413Z",
     "start_time": "2024-12-08T21:53:54.807810Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dst_path = \"/Users/sosen/UniProjects/eng-thesis/data/old/temp/CROPPED/NON-STED\"\n",
    "\n",
    "# Define parameters\n",
    "batch_size = 32\n",
    "\n",
    "img_height = 260\n",
    "img_width = 260"
   ],
   "id": "e3f43b8e49543d55",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:53:55.336597Z",
     "start_time": "2024-12-08T21:53:54.896715Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load the Data\n",
    "train_ds, val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    directory=dst_path,\n",
    "    labels='inferred',\n",
    "    subset=\"both\",\n",
    "    label_mode='categorical',\n",
    "    image_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    validation_split=0.2,\n",
    "    seed=123,\n",
    ")\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)"
   ],
   "id": "d4b28632c4653829",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2921 files belonging to 6 classes.\n",
      "Using 2337 files for training.\n",
      "Using 584 files for validation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:53:55.104831: I metal_plugin/src/device/metal_device.cc:1154] Metal device set to: Apple M3 Pro\n",
      "2024-12-08 22:53:55.104872: I metal_plugin/src/device/metal_device.cc:296] systemMemory: 18.00 GB\n",
      "2024-12-08 22:53:55.104883: I metal_plugin/src/device/metal_device.cc:313] maxCacheSize: 6.00 GB\n",
      "2024-12-08 22:53:55.104921: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-08 22:53:55.104950: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:53:55.349751Z",
     "start_time": "2024-12-08T21:53:55.346169Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def copy_red_to_green_and_blue(image,label):\n",
    "    \"\"\"\n",
    "    This function takes an image and replaces the green and blue channels \n",
    "    with the values from the red channel.\n",
    "    \"\"\"\n",
    "    # Repeat the red channel across the RGB channels\n",
    "    # image[..., 0] is the red channel of the image\n",
    "    red_channel = image[..., 0:1]  # Extract only the red channel, shape (H, W, 1)\n",
    "    new_image = tf.concat([red_channel, red_channel, red_channel], axis=-1)\n",
    "    return new_image, label"
   ],
   "id": "2fef72dbe3e95649",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:53:55.434220Z",
     "start_time": "2024-12-08T21:53:55.360491Z"
    }
   },
   "cell_type": "code",
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.prefetch(buffer_size=AUTOTUNE)\n",
    "train_ds = train_ds.map(copy_red_to_green_and_blue)\n",
    "val_ds = val_ds.map(copy_red_to_green_and_blue)"
   ],
   "id": "426eba66e126921c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:53:55.446838Z",
     "start_time": "2024-12-08T21:53:55.441727Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def precision(y_true, y_pred):\n",
    "        '''\n",
    "        Precision metric. Only computes a batch-wise average of precision. Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        '''\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    def recall(y_true, y_pred):\n",
    "        '''\n",
    "        Recall metric. Only computes a batch-wise average of recall. Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        '''\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    y_pred = K.round(y_pred)\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2 * ((precision * recall) / (precision + recall + K.epsilon()))"
   ],
   "id": "79ddc69db60964db",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:53:55.464720Z",
     "start_time": "2024-12-08T21:53:55.461880Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def normalize(x):\n",
    "    # mean = [0.485, 0.456, 0.406]\n",
    "    # std = [0.229, 0.224, 0.225]\n",
    "    mean = [0.24155269834305526,0.24155269834305526,0.24155269834305526]\n",
    "    std = [0.2809975193618667, 0.2809975193618667, 0.2809975193618667]\n",
    "    # mean = tf.constant([61.59593603488316, 61.59593603488316, 61.59593603488316])\n",
    "    # std = tf.constant([71.65436657360661, 71.65436657360661, 71.65436657360661])\n",
    "    return (x - mean) / std"
   ],
   "id": "31b1427554c472",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:53:55.484761Z",
     "start_time": "2024-12-08T21:53:55.475477Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data_augmentation = tf.keras.Sequential([\n",
    "    # tf.keras.layers.Lambda(copy_red_to_green_and_blue),\n",
    "    # tf.keras.layers.Rescaling(1. / 255),  # Scale images to [0, 1]\n",
    "    # tf.keras.layers.Lambda(normalize),  # Normalize images\n",
    "    # tf.keras.layers.Rescaling(scale=2, offset=-1),  # Scale images to [-1, 1]\n",
    "    # You can add more augmentations if needed\n",
    "    # tf.keras.layers.RandomZoom(0.15),\n",
    "    # tf.keras.layers.RandomWidth(0.1),\n",
    "    # tf.keras.layers.RandomHeight(0.1),\n",
    "    # tf.keras.layers.RandomContrast(0.05),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "], name=\"data_augmentation\")"
   ],
   "id": "cb2612e877afcb54",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:53:58.146346Z",
     "start_time": "2024-12-08T21:53:55.491871Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import layers\n",
    "\n",
    "inputs = layers.Input(shape=(img_height, img_width, 3))\n",
    "x = data_augmentation(inputs)\n",
    "\n",
    "model = tf.keras.applications.EfficientNetV2B0(weights='imagenet', include_top=False, input_tensor=x, pooling=None, include_preprocessing=True)\n",
    "model.trainable = False\n",
    "\n",
    "AVG_POOL_TOP = True\n",
    "if AVG_POOL_TOP:\n",
    "    # Rebuild top\n",
    "    x = layers.GlobalAveragePooling2D(name=\"avg_pool\")(model.output)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    top_dropout_rate = 0.2\n",
    "    x = layers.Dropout(top_dropout_rate, name=\"top_dropout\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\", name=\"pred\")(x)\n",
    "else:\n",
    "    x = Flatten()(model.output)\n",
    "    x = Dense(1000, activation='relu')(x)\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Compile\n",
    "model = tf.keras.Model(inputs, outputs, name=\"EfficientNet\")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy', f1])\n",
    "\n",
    "print(model.summary())"
   ],
   "id": "46bace3ebba27d4a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"EfficientNet\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(None, 260, 260, 3)]        0         []                            \n",
      "                                                                                                  \n",
      " data_augmentation (Sequent  (None, 260, 260, 3)          0         ['input_1[0][0]']             \n",
      " ial)                                                                                             \n",
      "                                                                                                  \n",
      " rescaling (Rescaling)       (None, 260, 260, 3)          0         ['data_augmentation[0][0]']   \n",
      "                                                                                                  \n",
      " normalization (Normalizati  (None, 260, 260, 3)          0         ['rescaling[0][0]']           \n",
      " on)                                                                                              \n",
      "                                                                                                  \n",
      " stem_conv (Conv2D)          (None, 130, 130, 32)         864       ['normalization[0][0]']       \n",
      "                                                                                                  \n",
      " stem_bn (BatchNormalizatio  (None, 130, 130, 32)         128       ['stem_conv[0][0]']           \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " stem_activation (Activatio  (None, 130, 130, 32)         0         ['stem_bn[0][0]']             \n",
      " n)                                                                                               \n",
      "                                                                                                  \n",
      " block1a_project_conv (Conv  (None, 130, 130, 16)         4608      ['stem_activation[0][0]']     \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block1a_project_bn (BatchN  (None, 130, 130, 16)         64        ['block1a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block1a_project_activation  (None, 130, 130, 16)         0         ['block1a_project_bn[0][0]']  \n",
      "  (Activation)                                                                                    \n",
      "                                                                                                  \n",
      " block2a_expand_conv (Conv2  (None, 65, 65, 64)           9216      ['block1a_project_activation[0\n",
      " D)                                                                 ][0]']                        \n",
      "                                                                                                  \n",
      " block2a_expand_bn (BatchNo  (None, 65, 65, 64)           256       ['block2a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2a_expand_activation   (None, 65, 65, 64)           0         ['block2a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block2a_project_conv (Conv  (None, 65, 65, 32)           2048      ['block2a_expand_activation[0]\n",
      " 2D)                                                                [0]']                         \n",
      "                                                                                                  \n",
      " block2a_project_bn (BatchN  (None, 65, 65, 32)           128       ['block2a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_expand_conv (Conv2  (None, 65, 65, 128)          36864     ['block2a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block2b_expand_bn (BatchNo  (None, 65, 65, 128)          512       ['block2b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block2b_expand_activation   (None, 65, 65, 128)          0         ['block2b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block2b_project_conv (Conv  (None, 65, 65, 32)           4096      ['block2b_expand_activation[0]\n",
      " 2D)                                                                [0]']                         \n",
      "                                                                                                  \n",
      " block2b_project_bn (BatchN  (None, 65, 65, 32)           128       ['block2b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block2b_drop (Dropout)      (None, 65, 65, 32)           0         ['block2b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block2b_add (Add)           (None, 65, 65, 32)           0         ['block2b_drop[0][0]',        \n",
      "                                                                     'block2a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block3a_expand_conv (Conv2  (None, 33, 33, 128)          36864     ['block2b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3a_expand_bn (BatchNo  (None, 33, 33, 128)          512       ['block3a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3a_expand_activation   (None, 33, 33, 128)          0         ['block3a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block3a_project_conv (Conv  (None, 33, 33, 48)           6144      ['block3a_expand_activation[0]\n",
      " 2D)                                                                [0]']                         \n",
      "                                                                                                  \n",
      " block3a_project_bn (BatchN  (None, 33, 33, 48)           192       ['block3a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_expand_conv (Conv2  (None, 33, 33, 192)          82944     ['block3a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block3b_expand_bn (BatchNo  (None, 33, 33, 192)          768       ['block3b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block3b_expand_activation   (None, 33, 33, 192)          0         ['block3b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block3b_project_conv (Conv  (None, 33, 33, 48)           9216      ['block3b_expand_activation[0]\n",
      " 2D)                                                                [0]']                         \n",
      "                                                                                                  \n",
      " block3b_project_bn (BatchN  (None, 33, 33, 48)           192       ['block3b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block3b_drop (Dropout)      (None, 33, 33, 48)           0         ['block3b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block3b_add (Add)           (None, 33, 33, 48)           0         ['block3b_drop[0][0]',        \n",
      "                                                                     'block3a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4a_expand_conv (Conv2  (None, 33, 33, 192)          9216      ['block3b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_expand_bn (BatchNo  (None, 33, 33, 192)          768       ['block4a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4a_expand_activation   (None, 33, 33, 192)          0         ['block4a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4a_dwconv2 (Depthwise  (None, 17, 17, 192)          1728      ['block4a_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block4a_bn (BatchNormaliza  (None, 17, 17, 192)          768       ['block4a_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4a_activation (Activa  (None, 17, 17, 192)          0         ['block4a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4a_se_squeeze (Global  (None, 192)                  0         ['block4a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4a_se_reshape (Reshap  (None, 1, 1, 192)            0         ['block4a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4a_se_reduce (Conv2D)  (None, 1, 1, 12)             2316      ['block4a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4a_se_expand (Conv2D)  (None, 1, 1, 192)            2496      ['block4a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4a_se_excite (Multipl  (None, 17, 17, 192)          0         ['block4a_activation[0][0]',  \n",
      " y)                                                                  'block4a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block4a_project_conv (Conv  (None, 17, 17, 96)           18432     ['block4a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4a_project_bn (BatchN  (None, 17, 17, 96)           384       ['block4a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_expand_conv (Conv2  (None, 17, 17, 384)          36864     ['block4a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4b_expand_bn (BatchNo  (None, 17, 17, 384)          1536      ['block4b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4b_expand_activation   (None, 17, 17, 384)          0         ['block4b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4b_dwconv2 (Depthwise  (None, 17, 17, 384)          3456      ['block4b_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block4b_bn (BatchNormaliza  (None, 17, 17, 384)          1536      ['block4b_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4b_activation (Activa  (None, 17, 17, 384)          0         ['block4b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4b_se_squeeze (Global  (None, 384)                  0         ['block4b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4b_se_reshape (Reshap  (None, 1, 1, 384)            0         ['block4b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4b_se_reduce (Conv2D)  (None, 1, 1, 24)             9240      ['block4b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4b_se_expand (Conv2D)  (None, 1, 1, 384)            9600      ['block4b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4b_se_excite (Multipl  (None, 17, 17, 384)          0         ['block4b_activation[0][0]',  \n",
      " y)                                                                  'block4b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block4b_project_conv (Conv  (None, 17, 17, 96)           36864     ['block4b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4b_project_bn (BatchN  (None, 17, 17, 96)           384       ['block4b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4b_drop (Dropout)      (None, 17, 17, 96)           0         ['block4b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4b_add (Add)           (None, 17, 17, 96)           0         ['block4b_drop[0][0]',        \n",
      "                                                                     'block4a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4c_expand_conv (Conv2  (None, 17, 17, 384)          36864     ['block4b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block4c_expand_bn (BatchNo  (None, 17, 17, 384)          1536      ['block4c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block4c_expand_activation   (None, 17, 17, 384)          0         ['block4c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block4c_dwconv2 (Depthwise  (None, 17, 17, 384)          3456      ['block4c_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block4c_bn (BatchNormaliza  (None, 17, 17, 384)          1536      ['block4c_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4c_activation (Activa  (None, 17, 17, 384)          0         ['block4c_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block4c_se_squeeze (Global  (None, 384)                  0         ['block4c_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block4c_se_reshape (Reshap  (None, 1, 1, 384)            0         ['block4c_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block4c_se_reduce (Conv2D)  (None, 1, 1, 24)             9240      ['block4c_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block4c_se_expand (Conv2D)  (None, 1, 1, 384)            9600      ['block4c_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block4c_se_excite (Multipl  (None, 17, 17, 384)          0         ['block4c_activation[0][0]',  \n",
      " y)                                                                  'block4c_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block4c_project_conv (Conv  (None, 17, 17, 96)           36864     ['block4c_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block4c_project_bn (BatchN  (None, 17, 17, 96)           384       ['block4c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block4c_drop (Dropout)      (None, 17, 17, 96)           0         ['block4c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block4c_add (Add)           (None, 17, 17, 96)           0         ['block4c_drop[0][0]',        \n",
      "                                                                     'block4b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block5a_expand_conv (Conv2  (None, 17, 17, 576)          55296     ['block4c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5a_expand_bn (BatchNo  (None, 17, 17, 576)          2304      ['block5a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5a_expand_activation   (None, 17, 17, 576)          0         ['block5a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5a_dwconv2 (Depthwise  (None, 17, 17, 576)          5184      ['block5a_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block5a_bn (BatchNormaliza  (None, 17, 17, 576)          2304      ['block5a_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5a_activation (Activa  (None, 17, 17, 576)          0         ['block5a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5a_se_squeeze (Global  (None, 576)                  0         ['block5a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5a_se_reshape (Reshap  (None, 1, 1, 576)            0         ['block5a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5a_se_reduce (Conv2D)  (None, 1, 1, 24)             13848     ['block5a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5a_se_expand (Conv2D)  (None, 1, 1, 576)            14400     ['block5a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5a_se_excite (Multipl  (None, 17, 17, 576)          0         ['block5a_activation[0][0]',  \n",
      " y)                                                                  'block5a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5a_project_conv (Conv  (None, 17, 17, 112)          64512     ['block5a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5a_project_bn (BatchN  (None, 17, 17, 112)          448       ['block5a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_expand_conv (Conv2  (None, 17, 17, 672)          75264     ['block5a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5b_expand_bn (BatchNo  (None, 17, 17, 672)          2688      ['block5b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5b_expand_activation   (None, 17, 17, 672)          0         ['block5b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5b_dwconv2 (Depthwise  (None, 17, 17, 672)          6048      ['block5b_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block5b_bn (BatchNormaliza  (None, 17, 17, 672)          2688      ['block5b_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5b_activation (Activa  (None, 17, 17, 672)          0         ['block5b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5b_se_squeeze (Global  (None, 672)                  0         ['block5b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5b_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block5b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5b_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block5b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5b_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block5b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5b_se_excite (Multipl  (None, 17, 17, 672)          0         ['block5b_activation[0][0]',  \n",
      " y)                                                                  'block5b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5b_project_conv (Conv  (None, 17, 17, 112)          75264     ['block5b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5b_project_bn (BatchN  (None, 17, 17, 112)          448       ['block5b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5b_drop (Dropout)      (None, 17, 17, 112)          0         ['block5b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5b_add (Add)           (None, 17, 17, 112)          0         ['block5b_drop[0][0]',        \n",
      "                                                                     'block5a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5c_expand_conv (Conv2  (None, 17, 17, 672)          75264     ['block5b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5c_expand_bn (BatchNo  (None, 17, 17, 672)          2688      ['block5c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5c_expand_activation   (None, 17, 17, 672)          0         ['block5c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5c_dwconv2 (Depthwise  (None, 17, 17, 672)          6048      ['block5c_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block5c_bn (BatchNormaliza  (None, 17, 17, 672)          2688      ['block5c_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5c_activation (Activa  (None, 17, 17, 672)          0         ['block5c_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5c_se_squeeze (Global  (None, 672)                  0         ['block5c_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5c_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block5c_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5c_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block5c_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5c_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block5c_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5c_se_excite (Multipl  (None, 17, 17, 672)          0         ['block5c_activation[0][0]',  \n",
      " y)                                                                  'block5c_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5c_project_conv (Conv  (None, 17, 17, 112)          75264     ['block5c_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5c_project_bn (BatchN  (None, 17, 17, 112)          448       ['block5c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5c_drop (Dropout)      (None, 17, 17, 112)          0         ['block5c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5c_add (Add)           (None, 17, 17, 112)          0         ['block5c_drop[0][0]',        \n",
      "                                                                     'block5b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block5d_expand_conv (Conv2  (None, 17, 17, 672)          75264     ['block5c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5d_expand_bn (BatchNo  (None, 17, 17, 672)          2688      ['block5d_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5d_expand_activation   (None, 17, 17, 672)          0         ['block5d_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5d_dwconv2 (Depthwise  (None, 17, 17, 672)          6048      ['block5d_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block5d_bn (BatchNormaliza  (None, 17, 17, 672)          2688      ['block5d_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5d_activation (Activa  (None, 17, 17, 672)          0         ['block5d_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5d_se_squeeze (Global  (None, 672)                  0         ['block5d_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5d_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block5d_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5d_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block5d_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5d_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block5d_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5d_se_excite (Multipl  (None, 17, 17, 672)          0         ['block5d_activation[0][0]',  \n",
      " y)                                                                  'block5d_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5d_project_conv (Conv  (None, 17, 17, 112)          75264     ['block5d_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5d_project_bn (BatchN  (None, 17, 17, 112)          448       ['block5d_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5d_drop (Dropout)      (None, 17, 17, 112)          0         ['block5d_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5d_add (Add)           (None, 17, 17, 112)          0         ['block5d_drop[0][0]',        \n",
      "                                                                     'block5c_add[0][0]']         \n",
      "                                                                                                  \n",
      " block5e_expand_conv (Conv2  (None, 17, 17, 672)          75264     ['block5d_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block5e_expand_bn (BatchNo  (None, 17, 17, 672)          2688      ['block5e_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block5e_expand_activation   (None, 17, 17, 672)          0         ['block5e_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block5e_dwconv2 (Depthwise  (None, 17, 17, 672)          6048      ['block5e_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block5e_bn (BatchNormaliza  (None, 17, 17, 672)          2688      ['block5e_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5e_activation (Activa  (None, 17, 17, 672)          0         ['block5e_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block5e_se_squeeze (Global  (None, 672)                  0         ['block5e_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block5e_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block5e_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block5e_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block5e_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block5e_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block5e_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block5e_se_excite (Multipl  (None, 17, 17, 672)          0         ['block5e_activation[0][0]',  \n",
      " y)                                                                  'block5e_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block5e_project_conv (Conv  (None, 17, 17, 112)          75264     ['block5e_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block5e_project_bn (BatchN  (None, 17, 17, 112)          448       ['block5e_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block5e_drop (Dropout)      (None, 17, 17, 112)          0         ['block5e_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block5e_add (Add)           (None, 17, 17, 112)          0         ['block5e_drop[0][0]',        \n",
      "                                                                     'block5d_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6a_expand_conv (Conv2  (None, 17, 17, 672)          75264     ['block5e_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_expand_bn (BatchNo  (None, 17, 17, 672)          2688      ['block6a_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6a_expand_activation   (None, 17, 17, 672)          0         ['block6a_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6a_dwconv2 (Depthwise  (None, 9, 9, 672)            6048      ['block6a_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6a_bn (BatchNormaliza  (None, 9, 9, 672)            2688      ['block6a_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6a_activation (Activa  (None, 9, 9, 672)            0         ['block6a_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6a_se_squeeze (Global  (None, 672)                  0         ['block6a_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6a_se_reshape (Reshap  (None, 1, 1, 672)            0         ['block6a_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6a_se_reduce (Conv2D)  (None, 1, 1, 28)             18844     ['block6a_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6a_se_expand (Conv2D)  (None, 1, 1, 672)            19488     ['block6a_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6a_se_excite (Multipl  (None, 9, 9, 672)            0         ['block6a_activation[0][0]',  \n",
      " y)                                                                  'block6a_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6a_project_conv (Conv  (None, 9, 9, 192)            129024    ['block6a_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6a_project_bn (BatchN  (None, 9, 9, 192)            768       ['block6a_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_expand_conv (Conv2  (None, 9, 9, 1152)           221184    ['block6a_project_bn[0][0]']  \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6b_expand_bn (BatchNo  (None, 9, 9, 1152)           4608      ['block6b_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6b_expand_activation   (None, 9, 9, 1152)           0         ['block6b_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6b_dwconv2 (Depthwise  (None, 9, 9, 1152)           10368     ['block6b_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6b_bn (BatchNormaliza  (None, 9, 9, 1152)           4608      ['block6b_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6b_activation (Activa  (None, 9, 9, 1152)           0         ['block6b_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6b_se_squeeze (Global  (None, 1152)                 0         ['block6b_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6b_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6b_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6b_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6b_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6b_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6b_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6b_se_excite (Multipl  (None, 9, 9, 1152)           0         ['block6b_activation[0][0]',  \n",
      " y)                                                                  'block6b_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6b_project_conv (Conv  (None, 9, 9, 192)            221184    ['block6b_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6b_project_bn (BatchN  (None, 9, 9, 192)            768       ['block6b_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6b_drop (Dropout)      (None, 9, 9, 192)            0         ['block6b_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6b_add (Add)           (None, 9, 9, 192)            0         ['block6b_drop[0][0]',        \n",
      "                                                                     'block6a_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6c_expand_conv (Conv2  (None, 9, 9, 1152)           221184    ['block6b_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6c_expand_bn (BatchNo  (None, 9, 9, 1152)           4608      ['block6c_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6c_expand_activation   (None, 9, 9, 1152)           0         ['block6c_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6c_dwconv2 (Depthwise  (None, 9, 9, 1152)           10368     ['block6c_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6c_bn (BatchNormaliza  (None, 9, 9, 1152)           4608      ['block6c_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6c_activation (Activa  (None, 9, 9, 1152)           0         ['block6c_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6c_se_squeeze (Global  (None, 1152)                 0         ['block6c_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6c_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6c_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6c_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6c_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6c_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6c_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6c_se_excite (Multipl  (None, 9, 9, 1152)           0         ['block6c_activation[0][0]',  \n",
      " y)                                                                  'block6c_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6c_project_conv (Conv  (None, 9, 9, 192)            221184    ['block6c_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6c_project_bn (BatchN  (None, 9, 9, 192)            768       ['block6c_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6c_drop (Dropout)      (None, 9, 9, 192)            0         ['block6c_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6c_add (Add)           (None, 9, 9, 192)            0         ['block6c_drop[0][0]',        \n",
      "                                                                     'block6b_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6d_expand_conv (Conv2  (None, 9, 9, 1152)           221184    ['block6c_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6d_expand_bn (BatchNo  (None, 9, 9, 1152)           4608      ['block6d_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6d_expand_activation   (None, 9, 9, 1152)           0         ['block6d_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6d_dwconv2 (Depthwise  (None, 9, 9, 1152)           10368     ['block6d_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6d_bn (BatchNormaliza  (None, 9, 9, 1152)           4608      ['block6d_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6d_activation (Activa  (None, 9, 9, 1152)           0         ['block6d_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6d_se_squeeze (Global  (None, 1152)                 0         ['block6d_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6d_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6d_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6d_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6d_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6d_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6d_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6d_se_excite (Multipl  (None, 9, 9, 1152)           0         ['block6d_activation[0][0]',  \n",
      " y)                                                                  'block6d_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6d_project_conv (Conv  (None, 9, 9, 192)            221184    ['block6d_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6d_project_bn (BatchN  (None, 9, 9, 192)            768       ['block6d_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6d_drop (Dropout)      (None, 9, 9, 192)            0         ['block6d_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6d_add (Add)           (None, 9, 9, 192)            0         ['block6d_drop[0][0]',        \n",
      "                                                                     'block6c_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6e_expand_conv (Conv2  (None, 9, 9, 1152)           221184    ['block6d_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6e_expand_bn (BatchNo  (None, 9, 9, 1152)           4608      ['block6e_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6e_expand_activation   (None, 9, 9, 1152)           0         ['block6e_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6e_dwconv2 (Depthwise  (None, 9, 9, 1152)           10368     ['block6e_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6e_bn (BatchNormaliza  (None, 9, 9, 1152)           4608      ['block6e_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6e_activation (Activa  (None, 9, 9, 1152)           0         ['block6e_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6e_se_squeeze (Global  (None, 1152)                 0         ['block6e_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6e_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6e_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6e_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6e_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6e_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6e_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6e_se_excite (Multipl  (None, 9, 9, 1152)           0         ['block6e_activation[0][0]',  \n",
      " y)                                                                  'block6e_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6e_project_conv (Conv  (None, 9, 9, 192)            221184    ['block6e_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6e_project_bn (BatchN  (None, 9, 9, 192)            768       ['block6e_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6e_drop (Dropout)      (None, 9, 9, 192)            0         ['block6e_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6e_add (Add)           (None, 9, 9, 192)            0         ['block6e_drop[0][0]',        \n",
      "                                                                     'block6d_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6f_expand_conv (Conv2  (None, 9, 9, 1152)           221184    ['block6e_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6f_expand_bn (BatchNo  (None, 9, 9, 1152)           4608      ['block6f_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6f_expand_activation   (None, 9, 9, 1152)           0         ['block6f_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6f_dwconv2 (Depthwise  (None, 9, 9, 1152)           10368     ['block6f_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6f_bn (BatchNormaliza  (None, 9, 9, 1152)           4608      ['block6f_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6f_activation (Activa  (None, 9, 9, 1152)           0         ['block6f_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6f_se_squeeze (Global  (None, 1152)                 0         ['block6f_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6f_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6f_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6f_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6f_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6f_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6f_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6f_se_excite (Multipl  (None, 9, 9, 1152)           0         ['block6f_activation[0][0]',  \n",
      " y)                                                                  'block6f_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6f_project_conv (Conv  (None, 9, 9, 192)            221184    ['block6f_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6f_project_bn (BatchN  (None, 9, 9, 192)            768       ['block6f_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6f_drop (Dropout)      (None, 9, 9, 192)            0         ['block6f_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6f_add (Add)           (None, 9, 9, 192)            0         ['block6f_drop[0][0]',        \n",
      "                                                                     'block6e_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6g_expand_conv (Conv2  (None, 9, 9, 1152)           221184    ['block6f_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6g_expand_bn (BatchNo  (None, 9, 9, 1152)           4608      ['block6g_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6g_expand_activation   (None, 9, 9, 1152)           0         ['block6g_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6g_dwconv2 (Depthwise  (None, 9, 9, 1152)           10368     ['block6g_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6g_bn (BatchNormaliza  (None, 9, 9, 1152)           4608      ['block6g_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6g_activation (Activa  (None, 9, 9, 1152)           0         ['block6g_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6g_se_squeeze (Global  (None, 1152)                 0         ['block6g_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6g_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6g_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6g_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6g_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6g_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6g_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6g_se_excite (Multipl  (None, 9, 9, 1152)           0         ['block6g_activation[0][0]',  \n",
      " y)                                                                  'block6g_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6g_project_conv (Conv  (None, 9, 9, 192)            221184    ['block6g_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6g_project_bn (BatchN  (None, 9, 9, 192)            768       ['block6g_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6g_drop (Dropout)      (None, 9, 9, 192)            0         ['block6g_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6g_add (Add)           (None, 9, 9, 192)            0         ['block6g_drop[0][0]',        \n",
      "                                                                     'block6f_add[0][0]']         \n",
      "                                                                                                  \n",
      " block6h_expand_conv (Conv2  (None, 9, 9, 1152)           221184    ['block6g_add[0][0]']         \n",
      " D)                                                                                               \n",
      "                                                                                                  \n",
      " block6h_expand_bn (BatchNo  (None, 9, 9, 1152)           4608      ['block6h_expand_conv[0][0]'] \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " block6h_expand_activation   (None, 9, 9, 1152)           0         ['block6h_expand_bn[0][0]']   \n",
      " (Activation)                                                                                     \n",
      "                                                                                                  \n",
      " block6h_dwconv2 (Depthwise  (None, 9, 9, 1152)           10368     ['block6h_expand_activation[0]\n",
      " Conv2D)                                                            [0]']                         \n",
      "                                                                                                  \n",
      " block6h_bn (BatchNormaliza  (None, 9, 9, 1152)           4608      ['block6h_dwconv2[0][0]']     \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6h_activation (Activa  (None, 9, 9, 1152)           0         ['block6h_bn[0][0]']          \n",
      " tion)                                                                                            \n",
      "                                                                                                  \n",
      " block6h_se_squeeze (Global  (None, 1152)                 0         ['block6h_activation[0][0]']  \n",
      " AveragePooling2D)                                                                                \n",
      "                                                                                                  \n",
      " block6h_se_reshape (Reshap  (None, 1, 1, 1152)           0         ['block6h_se_squeeze[0][0]']  \n",
      " e)                                                                                               \n",
      "                                                                                                  \n",
      " block6h_se_reduce (Conv2D)  (None, 1, 1, 48)             55344     ['block6h_se_reshape[0][0]']  \n",
      "                                                                                                  \n",
      " block6h_se_expand (Conv2D)  (None, 1, 1, 1152)           56448     ['block6h_se_reduce[0][0]']   \n",
      "                                                                                                  \n",
      " block6h_se_excite (Multipl  (None, 9, 9, 1152)           0         ['block6h_activation[0][0]',  \n",
      " y)                                                                  'block6h_se_expand[0][0]']   \n",
      "                                                                                                  \n",
      " block6h_project_conv (Conv  (None, 9, 9, 192)            221184    ['block6h_se_excite[0][0]']   \n",
      " 2D)                                                                                              \n",
      "                                                                                                  \n",
      " block6h_project_bn (BatchN  (None, 9, 9, 192)            768       ['block6h_project_conv[0][0]']\n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " block6h_drop (Dropout)      (None, 9, 9, 192)            0         ['block6h_project_bn[0][0]']  \n",
      "                                                                                                  \n",
      " block6h_add (Add)           (None, 9, 9, 192)            0         ['block6h_drop[0][0]',        \n",
      "                                                                     'block6g_add[0][0]']         \n",
      "                                                                                                  \n",
      " top_conv (Conv2D)           (None, 9, 9, 1280)           245760    ['block6h_add[0][0]']         \n",
      "                                                                                                  \n",
      " top_bn (BatchNormalization  (None, 9, 9, 1280)           5120      ['top_conv[0][0]']            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " top_activation (Activation  (None, 9, 9, 1280)           0         ['top_bn[0][0]']              \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " avg_pool (GlobalAveragePoo  (None, 1280)                 0         ['top_activation[0][0]']      \n",
      " ling2D)                                                                                          \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (None, 1280)                 5120      ['avg_pool[0][0]']            \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " top_dropout (Dropout)       (None, 1280)                 0         ['batch_normalization[0][0]'] \n",
      "                                                                                                  \n",
      " pred (Dense)                (None, 6)                    7686      ['top_dropout[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 5932118 (22.63 MB)\n",
      "Trainable params: 10246 (40.02 KB)\n",
      "Non-trainable params: 5921872 (22.59 MB)\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-08T21:54:23.387580Z",
     "start_time": "2024-12-08T21:53:58.155969Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Count occurrences of each class in the training dataset\n",
    "labels = np.concatenate([y for x, y in train_ds], axis=0)\n",
    "label_indices = np.argmax(labels, axis=1)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(label_indices),\n",
    "    y=label_indices\n",
    ")\n",
    "\n",
    "train_class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='f1',  # specify the F1 score for early stopping\n",
    "    patience=4,\n",
    "    mode='max',  #\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=20,\n",
    "    validation_data=val_ds,\n",
    "    class_weight=train_class_weights,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ],
   "id": "a4a2080b98a654ee",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:02.628044: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:117] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-12-08 22:54:03.118679: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/74 [..............................] - ETA: 6:42 - loss: 3.5931 - accuracy: 0.1250 - f1: 0.0851"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:05.337501: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3/74 [>.............................] - ETA: 15s - loss: 2.9799 - accuracy: 0.1667 - f1: 0.1157"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:05.550182: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:05.742640: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 5/74 [=>............................] - ETA: 14s - loss: 2.4984 - accuracy: 0.1500 - f1: 0.0950"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:05.941337: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:06.134277: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 6/74 [=>............................] - ETA: 13s - loss: 2.6188 - accuracy: 0.1510 - f1: 0.0927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:06.322214: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 8/74 [==>...........................] - ETA: 13s - loss: 2.3776 - accuracy: 0.1797 - f1: 0.1250"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:06.569320: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:06.769471: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 9/74 [==>...........................] - ETA: 13s - loss: 2.3642 - accuracy: 0.1979 - f1: 0.1435"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:06.951176: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/74 [===>..........................] - ETA: 13s - loss: 2.3373 - accuracy: 0.1969 - f1: 0.1422"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:07.210822: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/74 [===>..........................] - ETA: 13s - loss: 2.2576 - accuracy: 0.2057 - f1: 0.1628"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:07.438558: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:07.647958: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/74 [====>.........................] - ETA: 12s - loss: 2.1839 - accuracy: 0.2143 - f1: 0.1689"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:07.896021: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/74 [=====>........................] - ETA: 12s - loss: 2.1408 - accuracy: 0.2271 - f1: 0.1831"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:08.104745: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:08.297851: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/74 [=====>........................] - ETA: 12s - loss: 2.0524 - accuracy: 0.2537 - f1: 0.2047"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:08.512906: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:08.713571: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/74 [======>.......................] - ETA: 11s - loss: 1.9830 - accuracy: 0.2681 - f1: 0.2185"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:08.933030: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:09.123649: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/74 [=======>......................] - ETA: 11s - loss: 1.9464 - accuracy: 0.2672 - f1: 0.2175"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:09.307433: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/74 [=======>......................] - ETA: 10s - loss: 1.9361 - accuracy: 0.2770 - f1: 0.2300"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:09.523154: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:09.719649: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24/74 [========>.....................] - ETA: 10s - loss: 1.8867 - accuracy: 0.2839 - f1: 0.2338"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:09.912629: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:10.113344: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26/74 [=========>....................] - ETA: 10s - loss: 1.9040 - accuracy: 0.2825 - f1: 0.2318"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:10.323644: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:10.528226: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/74 [==========>...................] - ETA: 9s - loss: 1.8575 - accuracy: 0.2913 - f1: 0.2417"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:10.749818: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:10.941145: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/74 [==========>...................] - ETA: 9s - loss: 1.8399 - accuracy: 0.2931 - f1: 0.2463"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:11.158612: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/74 [===========>..................] - ETA: 9s - loss: 1.8102 - accuracy: 0.3014 - f1: 0.2570"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:11.417268: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:11.589663: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/74 [===========>..................] - ETA: 8s - loss: 1.7910 - accuracy: 0.3057 - f1: 0.2607"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:11.804593: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34/74 [============>.................] - ETA: 8s - loss: 1.7547 - accuracy: 0.3162 - f1: 0.2720"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:12.038293: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:12.232062: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35/74 [=============>................] - ETA: 8s - loss: 1.7368 - accuracy: 0.3223 - f1: 0.2742"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:12.440658: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37/74 [==============>...............] - ETA: 7s - loss: 1.7136 - accuracy: 0.3302 - f1: 0.2844"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:12.667204: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:12.855638: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/74 [==============>...............] - ETA: 7s - loss: 1.6943 - accuracy: 0.3347 - f1: 0.2885"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:13.058717: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40/74 [===============>..............] - ETA: 7s - loss: 1.6836 - accuracy: 0.3422 - f1: 0.2969"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:13.280275: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:13.479146: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/74 [===============>..............] - ETA: 6s - loss: 1.6675 - accuracy: 0.3476 - f1: 0.3027"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:13.687331: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43/74 [================>.............] - ETA: 6s - loss: 1.6660 - accuracy: 0.3517 - f1: 0.3088"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:13.908059: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:14.106753: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/74 [================>.............] - ETA: 6s - loss: 1.6568 - accuracy: 0.3558 - f1: 0.3127"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:14.328192: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46/74 [=================>............] - ETA: 5s - loss: 1.6282 - accuracy: 0.3655 - f1: 0.3228"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:14.569080: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:14.759974: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47/74 [==================>...........] - ETA: 5s - loss: 1.6285 - accuracy: 0.3677 - f1: 0.3271"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:14.961718: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49/74 [==================>...........] - ETA: 5s - loss: 1.6012 - accuracy: 0.3737 - f1: 0.3325"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:15.213048: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:15.409592: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50/74 [===================>..........] - ETA: 5s - loss: 1.5939 - accuracy: 0.3775 - f1: 0.3376"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:15.602641: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/74 [====================>.........] - ETA: 4s - loss: 1.6082 - accuracy: 0.3804 - f1: 0.3408"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:15.815860: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:15.978041: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/74 [====================>.........] - ETA: 4s - loss: 1.5848 - accuracy: 0.3883 - f1: 0.3467"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:16.176721: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/74 [=====================>........] - ETA: 3s - loss: 1.5704 - accuracy: 0.3915 - f1: 0.3505"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:16.378801: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/74 [=====================>........] - ETA: 3s - loss: 1.5595 - accuracy: 0.3929 - f1: 0.3530"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:16.587622: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:16.786218: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/74 [======================>.......] - ETA: 3s - loss: 1.5466 - accuracy: 0.3958 - f1: 0.3564"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:16.988791: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/74 [======================>.......] - ETA: 3s - loss: 1.5417 - accuracy: 0.3966 - f1: 0.3582"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:17.222743: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60/74 [=======================>......] - ETA: 2s - loss: 1.5211 - accuracy: 0.4016 - f1: 0.3634"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:17.434302: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:17.638750: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61/74 [=======================>......] - ETA: 2s - loss: 1.5078 - accuracy: 0.4052 - f1: 0.3676"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:17.873717: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63/74 [========================>.....] - ETA: 2s - loss: 1.4927 - accuracy: 0.4082 - f1: 0.3712"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:18.123037: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:18.320955: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65/74 [=========================>....] - ETA: 1s - loss: 1.4752 - accuracy: 0.4149 - f1: 0.3768"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:18.534088: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:18.723877: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66/74 [=========================>....] - ETA: 1s - loss: 1.4648 - accuracy: 0.4176 - f1: 0.3797"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:18.933914: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68/74 [==========================>...] - ETA: 1s - loss: 1.4418 - accuracy: 0.4265 - f1: 0.3872"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:19.178142: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:19.350125: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70/74 [===========================>..] - ETA: 0s - loss: 1.4248 - accuracy: 0.4313 - f1: 0.3930"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:19.524710: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71/74 [===========================>..] - ETA: 0s - loss: 1.4159 - accuracy: 0.4344 - f1: 0.3953"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:19.727468: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:19.921488: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/74 [============================>.] - ETA: 0s - loss: 1.3966 - accuracy: 0.4414 - f1: 0.4035"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-08 22:54:20.120688: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n",
      "2024-12-08 22:54:20.319672: I metal_plugin/src/kernels/stateless_random_op.cc:282] Note the GPU implementation does not produce the same series as CPU implementation.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 22\u001B[0m\n\u001B[1;32m     14\u001B[0m early_stopping \u001B[38;5;241m=\u001B[39m EarlyStopping(\n\u001B[1;32m     15\u001B[0m     monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m# specify the F1 score for early stopping\u001B[39;00m\n\u001B[1;32m     16\u001B[0m     patience\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m,\n\u001B[1;32m     17\u001B[0m     mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmax\u001B[39m\u001B[38;5;124m'\u001B[39m,  \u001B[38;5;66;03m#\u001B[39;00m\n\u001B[1;32m     18\u001B[0m     restore_best_weights\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[1;32m     19\u001B[0m )\n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Train the model\u001B[39;00m\n\u001B[0;32m---> 22\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     23\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtrain_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     24\u001B[0m \u001B[43m    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     25\u001B[0m \u001B[43m    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mval_ds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     26\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclass_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_class_weights\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     27\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mearly_stopping\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     28\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/keras/src/engine/training.py:1783\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1775\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1776\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1777\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1780\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1781\u001B[0m ):\n\u001B[1;32m   1782\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1783\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1784\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1785\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    828\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    830\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 831\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    833\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    834\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    864\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    865\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    866\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 867\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtracing_compilation\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    868\u001B[0m \u001B[43m      \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_no_variable_creation_config\u001B[49m\n\u001B[1;32m    869\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    870\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_variable_creation_config \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    871\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    872\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    873\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001B[0m, in \u001B[0;36mcall_function\u001B[0;34m(args, kwargs, tracing_options)\u001B[0m\n\u001B[1;32m    137\u001B[0m bound_args \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mbind(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    138\u001B[0m flat_inputs \u001B[38;5;241m=\u001B[39m function\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39munpack_inputs(bound_args)\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# pylint: disable=protected-access\u001B[39;49;00m\n\u001B[1;32m    140\u001B[0m \u001B[43m    \u001B[49m\u001B[43mflat_inputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\n\u001B[1;32m    141\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, tensor_inputs, captured_inputs)\u001B[0m\n\u001B[1;32m   1260\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1261\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1262\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1263\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1264\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1265\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1266\u001B[0m     args,\n\u001B[1;32m   1267\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1268\u001B[0m     executing_eagerly)\n\u001B[1;32m   1269\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001B[0m, in \u001B[0;36mAtomicFunction.flat_call\u001B[0;34m(self, args)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mflat_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args: Sequence[core\u001B[38;5;241m.\u001B[39mTensor]) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Any:\n\u001B[1;32m    216\u001B[0m \u001B[38;5;250m  \u001B[39m\u001B[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001B[39;00m\n\u001B[0;32m--> 217\u001B[0m   flat_outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    218\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfunction_type\u001B[38;5;241m.\u001B[39mpack_output(flat_outputs)\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001B[0m, in \u001B[0;36mAtomicFunction.__call__\u001B[0;34m(self, *args)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m record\u001B[38;5;241m.\u001B[39mstop_recording():\n\u001B[1;32m    251\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mexecuting_eagerly():\n\u001B[0;32m--> 252\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_bound_context\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall_function\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    254\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    255\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfunction_type\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflat_outputs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    256\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    257\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m make_call_op_in_graph(\n\u001B[1;32m    259\u001B[0m         \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    260\u001B[0m         \u001B[38;5;28mlist\u001B[39m(args),\n\u001B[1;32m    261\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_bound_context\u001B[38;5;241m.\u001B[39mfunction_call_options\u001B[38;5;241m.\u001B[39mas_attrs(),\n\u001B[1;32m    262\u001B[0m     )\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1479\u001B[0m, in \u001B[0;36mContext.call_function\u001B[0;34m(self, name, tensor_inputs, num_outputs)\u001B[0m\n\u001B[1;32m   1477\u001B[0m cancellation_context \u001B[38;5;241m=\u001B[39m cancellation\u001B[38;5;241m.\u001B[39mcontext()\n\u001B[1;32m   1478\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m cancellation_context \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 1479\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1480\u001B[0m \u001B[43m      \u001B[49m\u001B[43mname\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mutf-8\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1481\u001B[0m \u001B[43m      \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mnum_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1482\u001B[0m \u001B[43m      \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtensor_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1483\u001B[0m \u001B[43m      \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1484\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1485\u001B[0m \u001B[43m  \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1486\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   1487\u001B[0m   outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m   1488\u001B[0m       name\u001B[38;5;241m.\u001B[39mdecode(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mutf-8\u001B[39m\u001B[38;5;124m\"\u001B[39m),\n\u001B[1;32m   1489\u001B[0m       num_outputs\u001B[38;5;241m=\u001B[39mnum_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1493\u001B[0m       cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_context,\n\u001B[1;32m   1494\u001B[0m   )\n",
      "File \u001B[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:60\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     53\u001B[0m   \u001B[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001B[39;00m\n\u001B[1;32m     54\u001B[0m   inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     55\u001B[0m       tensor_conversion_registry\u001B[38;5;241m.\u001B[39mconvert(t)\n\u001B[1;32m     56\u001B[0m       \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(t, core_types\u001B[38;5;241m.\u001B[39mTensor)\n\u001B[1;32m     57\u001B[0m       \u001B[38;5;28;01melse\u001B[39;00m t\n\u001B[1;32m     58\u001B[0m       \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m inputs\n\u001B[1;32m     59\u001B[0m   ]\n\u001B[0;32m---> 60\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     61\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     63\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming model is already trained and compiled\n",
    "\n",
    "# Predict on validation data\n",
    "predictions = []\n",
    "y_true = []\n",
    "\n",
    "# Iterate over the validation dataset to collect true labels and predictions\n",
    "for images, labels in val_ds:\n",
    "    preds = model.predict(images)\n",
    "    predictions.extend(np.argmax(preds, axis=1))\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))  # Convert one-hot to integer labels\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "y_pred = np.array(predictions)\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ],
   "id": "9be9b6f264e712b2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "# Normalize the confusion matrix by dividing each row (true condition) by the sum of the row\n",
    "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "# Plotting the normalized confusion matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm_normalized, annot=True, fmt='.2f', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted labels')\n",
    "plt.ylabel('True labels')\n",
    "plt.title('Normalized Confusion Matrix')\n",
    "plt.show()"
   ],
   "id": "2afe1bfadf3d1f51",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "\n",
    "fig, axs = plt.subplots(3, figsize=(10, 15))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "axs[0].plot(history.history['accuracy'])\n",
    "axs[0].plot(history.history['val_accuracy'])\n",
    "axs[0].set_title('Model Accuracy')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend(['Train', 'Val'], loc='upper left')\n",
    "axs[0].set_xticks(range(0, len(history.history['accuracy']), max(1, len(history.history['accuracy']) // 10)))\n",
    "\n",
    "# Plot training & validation loss values\n",
    "axs[1].plot(history.history['loss'])\n",
    "axs[1].plot(history.history['val_loss'])\n",
    "axs[1].set_title('Model Loss')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend(['Train', 'Val'], loc='upper left')\n",
    "axs[1].set_xticks(range(0, len(history.history['loss']), max(1, len(history.history['loss']) // 10)))\n",
    "\n",
    "# Plot training & validation F1 score values\n",
    "axs[2].plot(history.history['f1'])\n",
    "axs[2].plot(history.history['val_f1'])\n",
    "axs[2].set_title('Model F1 Score')\n",
    "axs[2].set_ylabel('F1 Score')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].legend(['Train', 'Val'], loc='upper left')\n",
    "axs[2].set_xticks(range(0, len(history.history['f1']), max(1, len(history.history['f1']) // 10)))\n",
    "\n",
    "plt.tight_layout()  # Adjust layout to prevent overlap\n",
    "plt.show()\n",
    "\n",
    "plt.show()"
   ],
   "id": "bf0903a98eb0fcd2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def unfreeze_model(original_model):\n",
    "    # Clone the original model's architecture\n",
    "    # new_model = clone_model(original_model)\n",
    "    new_model = original_model\n",
    "    # Copy the weights from the original model to the new model\n",
    "    new_model.set_weights(original_model.get_weights())\n",
    "\n",
    "    # Unfreeze the top 10 layers, except for BatchNormalization layers\n",
    "    for layer in new_model.layers[-20:]:\n",
    "        if not isinstance(layer, layers.BatchNormalization):\n",
    "            layer.trainable = True\n",
    "\n",
    "    # Compile the new modeled with modified optimization settings\n",
    "    optimizer = Adam(learning_rate=1e-4)\n",
    "    new_model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=['accuracy', f1]  # ensure f1_metric is defined or imported\n",
    "    )\n",
    "\n",
    "    return new_model\n",
    "\n",
    "# Example usage:\n",
    "# Assuming `model` is your pre-trained model\n",
    "new_model = unfreeze_model(model)\n",
    "\n",
    "early_stopping_unfreeze = EarlyStopping(\n",
    "    monitor='f1',  # specify the F1 score for early stopping\n",
    "    patience=4,\n",
    "    mode='max',  #\n",
    "    restore_best_weights=True\n",
    ")\n",
    "epochs = 10  # @param {type: \"slider\", min:4, max:10}\n",
    "history_finetune = new_model.fit(train_ds, epochs=epochs, validation_data=val_ds, callbacks=[early_stopping])"
   ],
   "id": "2c449c6958d3a6fd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "fig, axs = plt.subplots(3, figsize=(10, 15))\n",
    "\n",
    "# Plot training & validation accuracy values\n",
    "axs[0].plot(history_finetune.history['accuracy'])\n",
    "axs[0].plot(history_finetune.history['val_accuracy'])\n",
    "axs[0].set_title('Model accuracy')\n",
    "axs[0].set_ylabel('Accuracy')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend(['Train', 'Val'], loc='upper left')\n",
    "\n",
    "# Plot training & validation loss values\n",
    "axs[1].plot(history_finetune.history['loss'])\n",
    "axs[1].plot(history_finetune.history['val_loss'])\n",
    "axs[1].set_title('Model loss')\n",
    "axs[1].set_ylabel('Loss')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend(['Train', 'Val'], loc='upper left')\n",
    "# Plot training & validation F1 score values\n",
    "axs[2].plot(history_finetune.history['f1'])\n",
    "axs[2].plot(history_finetune.history['val_f1'])\n",
    "axs[2].set_title('Model F1 Score')\n",
    "axs[2].set_ylabel('F1 Score')\n",
    "axs[2].set_xlabel('Epoch')\n",
    "axs[2].legend(['Train', 'Val'], loc='upper left')"
   ],
   "id": "d3073a844155d6cd",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "predictions = []\n",
    "y_true = []\n",
    "\n",
    "# Iterate over the validation dataset to collect true labels and predictions\n",
    "for images, labels in val_ds:\n",
    "    preds = new_model.predict(images)\n",
    "    predictions.extend(np.argmax(preds, axis=1))\n",
    "    y_true.extend(np.argmax(labels.numpy(), axis=1))  # Convert one-hot to integer labels\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "y_pred = np.array(predictions)\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "print(classification_report(y_true, y_pred, target_names=class_names))"
   ],
   "id": "73f3683c40714c21",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "1e18abdc41642dff",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
